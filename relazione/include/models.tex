\chapter{Modelli di Machine Learning}
Per lo sviluppo dei modelli di Machine Learning è stato utilizzato
\textit{caret}, un pacchetto contenente un insieme di funzioni in grado di 
creare modelli predittivi ed effettuare il train.

Sono stati scelti i seguenti modelli:
\begin{itemize}
    \item Support Vector Machine
    \item NaiveBayes
    \item Reti Neurali
\end{itemize}
La scelta di questi modelli è stata presa con la volontà di testare 
vari modelli di apprendimento supervisionato.\\
    
Le operazioni di train dei modelli elencati sono state effettuate 
per mezzo della 10 crossfold validation con tre ripetizioni. 
Anche per questa esecuzione si sono utilizzati 
gli strumenti messi a disposizione dal pacchetto \textit{caret}.

Per evitare che le predizioni eseguite fossero influenzate dai diversi tipi di misure 
presenti nel dataset si sono svolte delle operazioni si \textit{scaling} sui dati.\\

Si è considerata come positiva l'etichetta \textit{FALSE.POSITIVE}. \\
Nonostante questa considerazione vengono calcolate le misure di perfomance
al variare del numeratore nelle varie formule (precision, recall e 
f-measure) in modo da ottenere i valori per entrambe le classi.

\begin{mdframed}[backgroundcolor=yellow!20] 
    Si segnala che per tutti i modelli sono riportati i dati dell'ultima esecuzione.
\end{mdframed}

\section{Support Vector Machine}
Per le \textit{Support Vector Machine} si è scelto di sfruttare due diverse tipologie di Kernel:
\begin{itemize}
    \item Kernel Radiale
    \item Kernel Polinomiale
\end{itemize}
L'obiettivo è quello di provare a comprenderne eventuali miglioramenti prestazionali.

La libreria \textit{caret} si appoggia, per entrambi i kernel, alla libreria 
\textit{kernlab}.

\subsection{Kernel Radiale}
Il primo kernel testato è stato quello \textit{radiale}.
Per quanto rigurda il tuning, avendo ottenuto risultati positivi tramite il tuning automatico
effettuato da \textit{caret}, si è optato per lasciare questo tipo di tuning fornito 
direttamente dalla libreria.

Possiamo quindi osservare la matrice di confusione generata dal modello:
\begin{figure}[H]
    \centering
    \includegraphics[width = .5\textwidth]{../outputs/confusion_matrix_svmRadial.comparison.png}
    \caption{Fourfoldplot per la matrice di confusione ottenuta con svm e kernel radiale}
\end{figure}
A tale grafico sono correlate le seguenti misure di perfomance, oltre ad una 
\textit{accuracy} pari a $0.9603$:
\begin{center}
    \begin{tabular}{| c | c c c |} 
    \hline
    & Precision & Recall & F-Measure \\ [0.5ex] 
    \hline\hline
    CONFIRMED & 0.9490 & 0.9691 & 0.9589 \\ 
    \hline
    FALSE POSITIVE & 0.9711 & 0.9522 & 0.9616 \\ 
    \hline
    \end{tabular}
\end{center}
Si procede allo studio della curva ROC, per la classe "FALSE POSITIVE":
\begin{figure}[H]
    \centering
    \includegraphics[width = .5\textwidth]{../outputs/roc_svm_radial.comparison_FALSEPOSITIVE.png}
    \caption{Grafico con la ROC relativa alla classe "FALSE POSITIVE", ottenuta con svm e kernel radiale}
\end{figure}
\subsection{Kernel Polinomiale}
Il secondo kernel testato è stato quello \textit{polinomiale}.
Anche in questo caso, basandosi sulla qualità dei risultati, si è deciso di
lasciare il tuning automatico di default.

Possiamo quindi dare un primo sguardo alla matrice di confusione per valutare il modello:
\begin{figure}[H]
    \centering
    \includegraphics[width = .5\textwidth]{../outputs/confusion_matrix_svmPolynomial.comparison.png}
    \caption{Fourfoldplot per la matrice di confusione ottenuta con svm e kernel polinomiale}
\end{figure}

Le misure di perfomance correlate sono state, oltre ad una \textit{accuracy} 
pari a $0.9556$:
\begin{center}
    \begin{tabular}{| c | c c c |} 
    \hline  
    & Precision & Recall & F-Measure \\ [0.5ex] 
    \hline\hline
    CONFIRMED & 0.9358 & 0.9739 & 0.9545 \\ 
    \hline
    FALSE POSITIVE  & 0.9752 & 0.9388 & 0.9576 \\ 
    \hline
    \end{tabular}
\end{center}

Passiamo ora alla curva ROC, per la classe "FALSE POSITIVE":
\begin{figure}[H]
    \centering
    \includegraphics[width = .5\textwidth]{../outputs/roc_svm_polynomial.comparison_FALSEPOSITIVE.png}
    \caption{Grafico con la ROC relativa alla classe "FALSE POSITIVE" ottenuta con 
    svm e kernel polinomiale}
\end{figure}

\section{NaiveBayes}
Il secondo modello supervisionato usato è stato \textit{Naive Bayes}.

La libreria \textit{caret} utilizzata si appoggia per questo compito ad una 
differente libreria, \textit{naivebayes}.

Come già visto per le \textit{SVM}, anche in questo caso ci siamo affidati al tuning 
automatico offerto dalla libreria in quanto i risultati erano più che 
accettabili.

Si ottiene la seguente matrice di confusione:
\begin{figure}[H]
    \centering
    \includegraphics[width = .5\textwidth]{../outputs/confusion_matrix_bayes.comparison.png}
    \caption{Fourfoldplot per la matrice di confusione ottenuta con naive bayes}
\end{figure}
Passiamo quindi allo studio delle misura di perfomance.
Si ottengono con questo modello, oltre ad una \textit{accuracy} pari a $0.9245$:
\begin{center}
    \begin{tabular}{| c | c c c |} 
    \hline
    & Precision & Recall & F-Measure \\ [0.5ex] 
    \hline\hline
    CONFIRMED & 0.8899 & 0.9609 & 0.9240 \\ 
    \hline
    FALSE POSITIVE & 0.9614 & 0.8910 & 0.9249 \\ 
    \hline
    \end{tabular}
\end{center}

Viene quindi analizzata la curva ROC, per la classe "FALSE POSITIVE":
\begin{figure}[H]
    \centering
    \includegraphics[width = .5\textwidth]{../outputs/roc_bayes.comparison_FALSEPOSITIVE.png}
    \caption{Grafico con la ROC relativa alla classe "FALSE POSITIVE", ottenuta con 
    naive bayes}
\end{figure}
\section{Reti Neurali}
Per il terzo modello si è scelta la \textit{Rete Neurale}.
Si è scelto di usare il metodo \textit{nnet} della libreria \textit{caret}, 
che si appoggia sull'omonimo pacchetto \textit{nnet}.

Nel dettaglio si tratta di una rete a singolo layer che viene trainata 
usando come tuning quello di default offerto dalla libreria \textit{caret}.\\
La rete neurale presenta diverse problematiche in quanto non tutte le operazioni
di train, comunque effettuate sotto 10cv e con 3 ripetizioni, portano ad 
ottenere un buon modello predittivo. In queste situazioni si crea un modello 
che, a priori rispetto all'istanza, produce solamente una classe in output, 
portando ad avere una matrice di confusione con una delle due righe di soli 
valori zero (o comunque con valori poco superiori allo zero). Una probabile 
causa di questa situazione può essere ritrovata nella natura stessa del dataset, 
piccolo, e con classi probabilmente non facilmente separabili. 
Sono state tentate diverse configurazioni per risolvere il problema. Nonostante 
ciò la configurazione di tune di default si è rilevata essere la più efficace.\\
Trascurando quindi i casi in cui il modello non è in grado di distinguere le 
classi, comunque di frequenza ridotta, riportiamo la matrice di confusione:
\begin{figure}[H]
    \centering
    \includegraphics[width = .5\textwidth]{../outputs/confusion_matrix_network.comparison.png}
    \caption{Fourfoldplot per la matrice di confusione ottenuta con la rete neurale}
\end{figure}
Una tale matrice risulta "in linea" agli altri modelli. 
A riprova si ottengono le seguenti misure di perfomance, alle quali si aggiunge 
una \textit{accuracy} pari a $0.8777$:
\begin{center}
    \begin{tabular}{| c | c c c |} 
    \hline
    & Precision & Recall & F-Measure \\ [0.5ex] 
    \hline\hline
    CONFIRMED  & 0.8307 & 0.9349 & 0.8797 \\ 
    \hline
    FALSE POSITIVE & 0.9325 & 0.8254 & 0.8757 \\ 
    \hline
    \end{tabular}
\end{center}

Si segnala che nel caso si ottenesse un modello non in grado di distinguere le 
classi si avrebbe una accuracy pari a circa $0.5$.\\
Passiamo quindi, sempre nel caso in cui non si
abbia un modello non in grado di distinguere le classi, allo studio della curva 
ROC che per la classe "FALSE POSITIVE" risulta essere:
\begin{figure}[H]
    \centering
    \includegraphics[width = .5\textwidth]{../outputs/roc_network.comparison_FALSEPOSITIVE.png}
    \caption{Grafico con la ROC relativa alla classe "FALSE POSITIVE", ottenuta con 
    la rete neurale}
\end{figure}